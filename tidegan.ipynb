{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import SimpleNamespace\n",
    "import random\n",
    "import librosa\n",
    "import pescador\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2audio(audio_tensor):\n",
    "    audio_numpy = audio_tensor[0].cpu().float().numpy()\n",
    "    return audio_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_audio_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.cpu().state_dict(), save_path)\n",
    "        if len(gpu_ids) and torch.cuda.is_available():\n",
    "            network.cuda(gpu_ids[0])\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        network.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    # update learning rate (called once every epoch)\n",
    "    def update_learning_rate(self):\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate = %.7f' % lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.audio_examples = []\n",
    "\n",
    "    def query(self, audio_examples):\n",
    "        if self.pool_size == 0:\n",
    "            return Variable(audio_examples)\n",
    "        return_audio_examples = []\n",
    "        for audio_data in audio_examples:\n",
    "            audio_data = torch.unsqueeze(audio_data, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.audio_examples.append(audio_data)\n",
    "                return_audio_examples.append(audio_data)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.audio_examples[random_id].clone()\n",
    "                    self.audio_examples[random_id] = audio_data\n",
    "                    return_audio_examples.append(tmp)\n",
    "                else:\n",
    "                    return_audio_examples.append(audio_data)\n",
    "        return_audio_examples = Variable(torch.cat(return_audio_examples, 0))\n",
    "        return return_audio_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scheduler(optimizer, opt):\n",
    "    if opt.lr_policy == 'lambda':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'CycleGANModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        # load/define networks\n",
    "        # The naming conversion is different from those used in the paper\n",
    "        # Code (paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n",
    "        self.netG_A = WaveGANGenerator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                       num_channels=opt.num_channels,\n",
    "                                       latent_dim=opt.latent_dim, alpha=opt.alpha,\n",
    "                                       post_proc_filt_len=opt.post_proc_filt_len, verbose=opt.verbose)\n",
    "        self.netG_B = WaveGANGenerator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                       num_channels=opt.num_channels,\n",
    "                                       latent_dim=opt.latent_dim, alpha=opt.alpha,\n",
    "                                       post_proc_filt_len=opt.post_proc_filt_len, verbose=opt.verbose)\n",
    "\n",
    "        if self.isTrain:\n",
    "            use_sigmoid = opt.no_lsgan\n",
    "            self.netD_A = WaveGANDiscriminator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                               num_channels=opt.num_channels, shift_factor=opt.shift_factor,\n",
    "                                               alpha=opt.alpha, batch_shuffle=opt.batch_shuffle,\n",
    "                                               verbose=opt.verbose)\n",
    "            self.netD_B = WaveGANDiscriminator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                               num_channels=opt.num_channels, shift_factor=opt.shift_factor,\n",
    "                                               alpha=opt.alpha, batch_shuffle=opt.batch_shuffle,\n",
    "                                               verbose=opt.verbose)\n",
    "            \n",
    "\n",
    "        if self.isTrain:\n",
    "            self.fake_A_pool = AudioPool(opt.pool_size)\n",
    "            self.fake_B_pool = AudioPool(opt.pool_size)\n",
    "            # define loss functions\n",
    "            self.criterionGAN = GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n",
    "            self.criterionCycle = torch.nn.L1Loss()\n",
    "            self.criterionIdt = torch.nn.L1Loss()\n",
    "            # initialize optimizers\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n",
    "                                                lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizers = []\n",
    "            self.schedulers = []\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D_A)\n",
    "            self.optimizers.append(self.optimizer_D_B)\n",
    "            for optimizer in self.optimizers:\n",
    "                self.schedulers.append(get_scheduler(optimizer, opt))\n",
    "\n",
    "        print('---------- Networks initialized -------------')\n",
    "        print_network(self.netG_A)\n",
    "        print_network(self.netG_B)\n",
    "        if self.isTrain:\n",
    "            print_network(self.netD_A)\n",
    "            print_network(self.netD_B)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "    def set_input(self, input):\n",
    "        AtoB = self.opt.which_direction == 'AtoB'\n",
    "        input_A = input['A' if AtoB else 'B']\n",
    "        input_B = input['B' if AtoB else 'A']\n",
    "        if len(self.gpu_ids) > 0:\n",
    "            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n",
    "            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n",
    "        self.input_A = input_A\n",
    "        self.input_B = input_B\n",
    "        self.audio_paths = input['A_paths' if AtoB else 'B_paths']\n",
    "\n",
    "    def forward(self):\n",
    "        self.real_A = Variable(self.input_A)\n",
    "        self.real_B = Variable(self.input_B)\n",
    "\n",
    "    def test(self):\n",
    "        real_A = Variable(self.input_A, volatile=True)\n",
    "        fake_B = self.netG_A(real_A)\n",
    "        self.rec_A = self.netG_B(fake_B).data\n",
    "        self.fake_B = fake_B.data\n",
    "\n",
    "        real_B = Variable(self.input_B, volatile=True)\n",
    "        fake_A = self.netG_B(real_B)\n",
    "        self.rec_B = self.netG_A(fake_A).data\n",
    "        self.fake_A = fake_A.data\n",
    "\n",
    "    # get audio paths\n",
    "    def get_audio_paths(self):\n",
    "        return self.audio_paths\n",
    "\n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        # backward\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "\n",
    "    def backward_D_A(self):\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "        self.loss_D_A = loss_D_A.data[0]\n",
    "\n",
    "    def backward_D_B(self):\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "        self.loss_D_B = loss_D_B.data[0]\n",
    "\n",
    "    def backward_G(self):\n",
    "        lambda_idt = self.opt.lambda_identity\n",
    "        lambda_A = self.opt.lambda_A\n",
    "        lambda_B = self.opt.lambda_B\n",
    "        # Identity loss\n",
    "        if lambda_idt > 0:\n",
    "            # G_A should be identity if real_B is fed.\n",
    "            idt_A = self.netG_A(self.real_B)\n",
    "            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # G_B should be identity if real_A is fed.\n",
    "            idt_B = self.netG_B(self.real_A)\n",
    "            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "\n",
    "            self.idt_A = idt_A.data\n",
    "            self.idt_B = idt_B.data\n",
    "            self.loss_idt_A = loss_idt_A.data[0]\n",
    "            self.loss_idt_B = loss_idt_B.data[0]\n",
    "        else:\n",
    "            loss_idt_A = 0\n",
    "            loss_idt_B = 0\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        fake_B = self.netG_A(self.real_A)\n",
    "        pred_fake = self.netD_A(fake_B)\n",
    "        loss_G_A = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        fake_A = self.netG_B(self.real_B)\n",
    "        pred_fake = self.netD_B(fake_A)\n",
    "        loss_G_B = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # Forward cycle loss\n",
    "        rec_A = self.netG_B(fake_B)\n",
    "        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n",
    "\n",
    "        # Backward cycle loss\n",
    "        rec_B = self.netG_A(fake_A)\n",
    "        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n",
    "        # combined loss\n",
    "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n",
    "        loss_G.backward()\n",
    "\n",
    "        self.fake_B = fake_B.data\n",
    "        self.fake_A = fake_A.data\n",
    "        self.rec_A = rec_A.data\n",
    "        self.rec_B = rec_B.data\n",
    "\n",
    "        self.loss_G_A = loss_G_A.data[0]\n",
    "        self.loss_G_B = loss_G_B.data[0]\n",
    "        self.loss_cycle_A = loss_cycle_A.data[0]\n",
    "        self.loss_cycle_B = loss_cycle_B.data[0]\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        # forward\n",
    "        self.forward()\n",
    "        # G_A and G_B\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "        # D_A\n",
    "        self.optimizer_D_A.zero_grad()\n",
    "        self.backward_D_A()\n",
    "        self.optimizer_D_A.step()\n",
    "        # D_B\n",
    "        self.optimizer_D_B.zero_grad()\n",
    "        self.backward_D_B()\n",
    "        self.optimizer_D_B.step()\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n",
    "                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n",
    "        if self.opt.lambda_identity > 0.0:\n",
    "            ret_errors['idt_A'] = self.loss_idt_A\n",
    "            ret_errors['idt_B'] = self.loss_idt_B\n",
    "        return ret_errors\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        real_A = util.tensor2audio(self.input_A)\n",
    "        fake_B = util.tensor2audio(self.fake_B)\n",
    "        rec_A = util.tensor2audio(self.rec_A)\n",
    "        real_B = util.tensor2audio(self.input_B)\n",
    "        fake_A = util.tensor2audio(self.fake_A)\n",
    "        rec_B = util.tensor2audio(self.rec_B)\n",
    "        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n",
    "                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n",
    "        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n",
    "            ret_visuals['idt_A'] = util.tensor2audio(self.idt_A)\n",
    "            ret_visuals['idt_B'] = util.tensor2audio(self.idt_B)\n",
    "        return ret_visuals\n",
    "\n",
    "    def save(self, label):\n",
    "        self.save_network(self.netG_A, 'G_A', label, self.gpu_ids)\n",
    "        self.save_network(self.netD_A, 'D_A', label, self.gpu_ids)\n",
    "        self.save_network(self.netG_B, 'G_B', label, self.gpu_ids)\n",
    "        self.save_network(self.netD_B, 'D_B', label, self.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the GAN loss which uses either LSGAN or the regular GAN.\n",
    "# When LSGAN is used, it is basically same as MSELoss,\n",
    "# but it abstracts away the need to create the target label tensor\n",
    "# that has the same size as the input\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n",
    "                 tensor=torch.FloatTensor):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = target_real_label\n",
    "        self.fake_label = target_fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.Tensor = tensor\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or\n",
    "                            (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or\n",
    "                            (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGANGenerator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, latent_dim=100, alpha=0.2,\n",
    "                 post_proc_filt_len=512, verbose=False):\n",
    "        super(WaveGANGenerator, self).__init__()\n",
    "        self.ngpus = ngpus\n",
    "        self.model_size = model_size # d\n",
    "        self.num_channels = num_channels # c\n",
    "        self.latent_dim = latent_dim\n",
    "        self.post_proc_filt_len = post_proc_filt_len\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, latent_dim))\n",
    "        self.fc2 = nn.DataParallel(nn.Linear(latent_dim, 256 * model_size))\n",
    "\n",
    "        self.tconv1 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(16 * model_size, 8 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv2 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(8 * model_size, 4 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv3 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(4 * model_size, 2 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv4 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(2 * model_size, model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv5 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(model_size, num_channels, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "\n",
    "        if post_proc_filt_len:\n",
    "            self.ppfilter1 = nn.DataParallel(nn.Conv1d(num_channels, num_channels, post_proc_filt_len))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x)).view(-1, 16 * self.model_size, 16)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv3(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv4(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        output = F.tanh(self.tconv5(x))\n",
    "        if self.verbose:\n",
    "            print(output.shape)\n",
    "\n",
    "        if self.post_proc_filt_len:\n",
    "            # Pad for \"same\" filtering\n",
    "            if (self.post_proc_filt_len % 2) == 0:\n",
    "                pad_left = self.post_proc_filt_len // 2\n",
    "                pad_right = pad_left - 1\n",
    "            else:\n",
    "                pad_left = (self.post_proc_filt_len - 1) // 2\n",
    "                pad_right = pad_left\n",
    "            output = self.ppfilter1(F.pad(output, (pad_left, pad_right)))\n",
    "            if self.verbose:\n",
    "                print(output.shape)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
    "    by a random integer in {-n, n} and performing reflection padding where\n",
    "    necessary\n",
    "    \"\"\"\n",
    "    def __init__(self, n, batch_shuffle=True):\n",
    "        super(PhaseShuffle, self).__init__()\n",
    "        self.n = n\n",
    "        self.batch_shuffle = batch_shuffle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Make sure to use PyTorch to generate number RNG state is all shared\n",
    "        if self.batch_shuffle:                                                              \n",
    "            # Make sure to use PyTorcTrueh to generate number RNG state is all shared       \n",
    "            k = int(torch.Tensor(1).random_(0, 2*self.n + 1)) - self.n\n",
    "\n",
    "            # Return if no phase shift                                                      \n",
    "            if k == 0:                                                                      \n",
    "                return x                                                                    \n",
    "\n",
    "            # Slice feature dimension                                                       \n",
    "            if k > 0:                                                                       \n",
    "                x_trunc = x[:, :, :-k]                                                      \n",
    "                pad = (k, 0)                                                                \n",
    "            else:                                                                           \n",
    "                x_trunc = x[:, :, -k:]                                                      \n",
    "                pad = (0, -k)                                                               \n",
    "\n",
    "            # Reflection padding                                                            \n",
    "            x_shuffle = F.pad(x_trunc, pad, mode='reflect')                                 \n",
    "\n",
    "        else:                                                                               \n",
    "            k_list = torch.Tensor(x.shape[0]).random_(0, 2*self.n+1) - self.n                                                         \n",
    "            k_list = k_list.numpy().astype(int)                                             \n",
    "            x_shuffle = x.clone()                                                           \n",
    "\n",
    "            for idx, k in enumerate(k_list):                                                \n",
    "                k = int(k)                                                                  \n",
    "                if k > 0:                                                                   \n",
    "                    xi_trunc = x[idx:idx+1, :, :-k]                                         \n",
    "                    pad = (k, 0)                                                            \n",
    "                else:                                                                       \n",
    "                    xi_trunc = x[idx:idx+1, :, -k:]                                         \n",
    "                    pad = (0, -k)                                                           \n",
    "\n",
    "                x_shuffle[idx:idx+1] = F.pad(xi_trunc, pad, mode='reflect')                 \n",
    "\n",
    "\n",
    "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape, x.shape)\n",
    "        return x_shuffle\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGANDiscriminator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2, alpha=0.2, batch_shuffle=False, verbose=False):\n",
    "        super(WaveGANDiscriminator, self).__init__()\n",
    "        self.model_size = model_size # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels # c\n",
    "        self.shift_factor = shift_factor # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, etc.)\n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "        self.ps1 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps2 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps3 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps4 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, 1))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps4(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        return F.sigmoid(self.fc1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sample_generator(filepath, window_length=16384, fs=16000):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(filepath, sr=fs)\n",
    "    except Exception as e:\n",
    "        raise StopIteration()\n",
    "        \n",
    "    audio_len = len(audio_data)\n",
    "    \n",
    "    # Pad audio to at least a single frame\n",
    "    if audio_len < window_length:\n",
    "        pad_length = window_length - audio_len\n",
    "        left_pad = pad_length // 2\n",
    "        right_pad = pad_length - left_pad\n",
    "        \n",
    "        audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
    "        audio_len = len(audio_data)\n",
    "        \n",
    "    while True:\n",
    "        if audio_len == window_length:\n",
    "            # If we only have a single frame's worth of audio, just yield the whole audio\n",
    "            sample = audio_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0,audio_len - window_length)\n",
    "            end_idx = start_idx + window_length\n",
    "            sample = audio_data[start_idx:end_idx]\n",
    "            \n",
    "        sample = sample.astype('float32')\n",
    "        assert not np.any(np.isnan(sample))\n",
    "            \n",
    "        yield {'X': sample}\n",
    "    \n",
    "def create_batch_generator(audio_filepath_list, batch_size):\n",
    "    streamers = []\n",
    "    for audio_filepath in audio_filepath_list:\n",
    "        s = pescador.Streamer(file_sample_generator, audio_filepath)\n",
    "        streamers.append(s)\n",
    "        \n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    \n",
    "    return batch_gen\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir)\n",
    "            for fname in file_names\n",
    "            if fname.lower().endswith('.wav')]\n",
    "\n",
    "def create_data_split(audio_filepath_list, valid_ratio, test_ratio, train_batch_size, valid_size, test_size):\n",
    "    num_files = len(audio_filepath_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "    \n",
    "    assert num_valid > 0\n",
    "    assert num_test > 0\n",
    "    assert num_train > 0\n",
    "    \n",
    "    valid_files = audio_filepath_list[:num_valid]\n",
    "    test_files = audio_filepath_list[num_valid:num_valid+num_test]\n",
    "    train_files = audio_filepath_list[num_valid+num_test:]\n",
    "    \n",
    "    train_gen = create_batch_generator(train_files, train_batch_size)\n",
    "    valid_data = next(iter(create_batch_generator(valid_files, valid_size)))\n",
    "    test_data = next(iter(create_batch_generator(train_files, test_size)))\n",
    "    \n",
    "    return train_gen, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_input_tensor(data, use_cuda):\n",
    "    data = data[:,np.newaxis,:]\n",
    "    data = torch.Tensor(data)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "audio_dir_A = \"/beegfs/jtc440/aml/TheDrumClub-Kit004-THEMEGABUNDLE/Rhodes Polaris\"\n",
    "audio_filepaths_A = get_all_audio_filepaths(audio_dir_A)\n",
    "genA, valid_data_A, test_data_A = create_data_split(audio_filepaths_A, 0.1, 0.1, batch_size, 64, 64)\n",
    "\n",
    "audio_dir_B = \"/beegfs/jtc440/aml/TheDrumClub-Kit004-THEMEGABUNDLE/Korg M1\"\n",
    "audio_filepaths_B = get_all_audio_filepaths(audio_dir_B)\n",
    "genB, valid_data_B, test_data_B = create_data_split(audio_filepaths_B, 0.1, 0.1, batch_size, 64, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "WaveGANGenerator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=100, bias=True)\n",
      "  )\n",
      "  (fc2): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (tconv1): DataParallel(\n",
      "    (module): ConvTranspose1d(1024, 512, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv2): DataParallel(\n",
      "    (module): ConvTranspose1d(512, 256, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv3): DataParallel(\n",
      "    (module): ConvTranspose1d(256, 128, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv4): DataParallel(\n",
      "    (module): ConvTranspose1d(128, 64, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv5): DataParallel(\n",
      "    (module): ConvTranspose1d(64, 1, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 38115942\n",
      "WaveGANGenerator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=100, bias=True)\n",
      "  )\n",
      "  (fc2): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (tconv1): DataParallel(\n",
      "    (module): ConvTranspose1d(1024, 512, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv2): DataParallel(\n",
      "    (module): ConvTranspose1d(512, 256, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv3): DataParallel(\n",
      "    (module): ConvTranspose1d(256, 128, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv4): DataParallel(\n",
      "    (module): ConvTranspose1d(128, 64, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv5): DataParallel(\n",
      "    (module): ConvTranspose1d(64, 1, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 38115942\n",
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 17427969\n",
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 17427969\n",
      "-----------------------------------------------\n",
      "saving the latest model (epoch 0, total_steps 64)\n",
      "saving the latest model (epoch 0, total_steps 128)\n",
      "saving the latest model (epoch 0, total_steps 192)\n",
      "saving the latest model (epoch 0, total_steps 256)\n",
      "saving the latest model (epoch 0, total_steps 320)\n",
      "saving the latest model (epoch 0, total_steps 384)\n",
      "saving the latest model (epoch 0, total_steps 448)\n",
      "saving the latest model (epoch 0, total_steps 512)\n",
      "saving the latest model (epoch 0, total_steps 576)\n",
      "saving the latest model (epoch 0, total_steps 640)\n",
      "saving the model at the end of epoch 0, iters 640\n",
      "End of epoch 0 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 1, total_steps 704)\n",
      "saving the latest model (epoch 1, total_steps 768)\n",
      "saving the latest model (epoch 1, total_steps 832)\n",
      "saving the latest model (epoch 1, total_steps 896)\n",
      "saving the latest model (epoch 1, total_steps 960)\n",
      "saving the latest model (epoch 1, total_steps 1024)\n",
      "saving the latest model (epoch 1, total_steps 1088)\n",
      "saving the latest model (epoch 1, total_steps 1152)\n",
      "saving the latest model (epoch 1, total_steps 1216)\n",
      "saving the latest model (epoch 1, total_steps 1280)\n",
      "saving the model at the end of epoch 1, iters 1280\n",
      "End of epoch 1 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 2, total_steps 1344)\n",
      "saving the latest model (epoch 2, total_steps 1408)\n",
      "saving the latest model (epoch 2, total_steps 1472)\n",
      "saving the latest model (epoch 2, total_steps 1536)\n",
      "saving the latest model (epoch 2, total_steps 1600)\n",
      "saving the latest model (epoch 2, total_steps 1664)\n",
      "saving the latest model (epoch 2, total_steps 1728)\n",
      "saving the latest model (epoch 2, total_steps 1792)\n",
      "saving the latest model (epoch 2, total_steps 1856)\n",
      "saving the latest model (epoch 2, total_steps 1920)\n",
      "saving the model at the end of epoch 2, iters 1920\n",
      "End of epoch 2 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 3, total_steps 1984)\n",
      "saving the latest model (epoch 3, total_steps 2048)\n",
      "saving the latest model (epoch 3, total_steps 2112)\n",
      "saving the latest model (epoch 3, total_steps 2176)\n",
      "saving the latest model (epoch 3, total_steps 2240)\n",
      "saving the latest model (epoch 3, total_steps 2304)\n",
      "saving the latest model (epoch 3, total_steps 2368)\n",
      "saving the latest model (epoch 3, total_steps 2432)\n",
      "saving the latest model (epoch 3, total_steps 2496)\n",
      "saving the latest model (epoch 3, total_steps 2560)\n",
      "saving the model at the end of epoch 3, iters 2560\n",
      "End of epoch 3 / 10 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 4, total_steps 2624)\n",
      "saving the latest model (epoch 4, total_steps 2688)\n",
      "saving the latest model (epoch 4, total_steps 2752)\n",
      "saving the latest model (epoch 4, total_steps 2816)\n",
      "saving the latest model (epoch 4, total_steps 2880)\n",
      "saving the latest model (epoch 4, total_steps 2944)\n",
      "saving the latest model (epoch 4, total_steps 3008)\n",
      "saving the latest model (epoch 4, total_steps 3072)\n",
      "saving the latest model (epoch 4, total_steps 3136)\n",
      "saving the latest model (epoch 4, total_steps 3200)\n",
      "saving the model at the end of epoch 4, iters 3200\n",
      "End of epoch 4 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 5, total_steps 3264)\n",
      "saving the latest model (epoch 5, total_steps 3328)\n",
      "saving the latest model (epoch 5, total_steps 3392)\n",
      "saving the latest model (epoch 5, total_steps 3456)\n",
      "saving the latest model (epoch 5, total_steps 3520)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the latest model (epoch 5, total_steps 3584)\n",
      "saving the latest model (epoch 5, total_steps 3648)\n",
      "saving the latest model (epoch 5, total_steps 3712)\n",
      "saving the latest model (epoch 5, total_steps 3776)\n",
      "saving the latest model (epoch 5, total_steps 3840)\n",
      "saving the model at the end of epoch 5, iters 3840\n",
      "End of epoch 5 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 6, total_steps 3904)\n",
      "saving the latest model (epoch 6, total_steps 3968)\n",
      "saving the latest model (epoch 6, total_steps 4032)\n",
      "saving the latest model (epoch 6, total_steps 4096)\n",
      "saving the latest model (epoch 6, total_steps 4160)\n",
      "saving the latest model (epoch 6, total_steps 4224)\n",
      "saving the latest model (epoch 6, total_steps 4288)\n",
      "saving the latest model (epoch 6, total_steps 4352)\n",
      "saving the latest model (epoch 6, total_steps 4416)\n",
      "saving the latest model (epoch 6, total_steps 4480)\n",
      "saving the model at the end of epoch 6, iters 4480\n",
      "End of epoch 6 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 7, total_steps 4544)\n",
      "saving the latest model (epoch 7, total_steps 4608)\n",
      "saving the latest model (epoch 7, total_steps 4672)\n",
      "saving the latest model (epoch 7, total_steps 4736)\n",
      "saving the latest model (epoch 7, total_steps 4800)\n",
      "saving the latest model (epoch 7, total_steps 4864)\n",
      "saving the latest model (epoch 7, total_steps 4928)\n",
      "saving the latest model (epoch 7, total_steps 4992)\n",
      "saving the latest model (epoch 7, total_steps 5056)\n",
      "saving the latest model (epoch 7, total_steps 5120)\n",
      "saving the model at the end of epoch 7, iters 5120\n",
      "End of epoch 7 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 8, total_steps 5184)\n",
      "saving the latest model (epoch 8, total_steps 5248)\n",
      "saving the latest model (epoch 8, total_steps 5312)\n",
      "saving the latest model (epoch 8, total_steps 5376)\n",
      "saving the latest model (epoch 8, total_steps 5440)\n",
      "saving the latest model (epoch 8, total_steps 5504)\n",
      "saving the latest model (epoch 8, total_steps 5568)\n",
      "saving the latest model (epoch 8, total_steps 5632)\n",
      "saving the latest model (epoch 8, total_steps 5696)\n",
      "saving the latest model (epoch 8, total_steps 5760)\n",
      "saving the model at the end of epoch 8, iters 5760\n",
      "End of epoch 8 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 9, total_steps 5824)\n",
      "saving the latest model (epoch 9, total_steps 5888)\n",
      "saving the latest model (epoch 9, total_steps 5952)\n",
      "saving the latest model (epoch 9, total_steps 6016)\n",
      "saving the latest model (epoch 9, total_steps 6080)\n",
      "saving the latest model (epoch 9, total_steps 6144)\n",
      "saving the latest model (epoch 9, total_steps 6208)\n",
      "saving the latest model (epoch 9, total_steps 6272)\n",
      "saving the latest model (epoch 9, total_steps 6336)\n",
      "saving the latest model (epoch 9, total_steps 6400)\n",
      "saving the model at the end of epoch 9, iters 6400\n",
      "End of epoch 9 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 10, total_steps 6464)\n",
      "saving the latest model (epoch 10, total_steps 6528)\n",
      "saving the latest model (epoch 10, total_steps 6592)\n",
      "saving the latest model (epoch 10, total_steps 6656)\n",
      "saving the latest model (epoch 10, total_steps 6720)\n",
      "saving the latest model (epoch 10, total_steps 6784)\n",
      "saving the latest model (epoch 10, total_steps 6848)\n",
      "saving the latest model (epoch 10, total_steps 6912)\n",
      "saving the latest model (epoch 10, total_steps 6976)\n",
      "saving the latest model (epoch 10, total_steps 7040)\n",
      "saving the model at the end of epoch 10, iters 7040\n",
      "End of epoch 10 / 10 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "opt = SimpleNamespace(\n",
    "    epoch_count=0,\n",
    "    niter=10,\n",
    "    niter_decay = 0,\n",
    "    print_freq = 1,\n",
    "    batchSize = batch_size,\n",
    "    display_freq = 1,\n",
    "    update_html_freq = 1,\n",
    "    display_id = 4,\n",
    "    save_latest_freq = 1,\n",
    "    isTrain = True,\n",
    "    gpu_ids = list(range(torch.cuda.device_count())),\n",
    "    checkpoints_dir='/scratch/jtc440/cyclegan',\n",
    "    name='tidegan',\n",
    "    model_size=64,\n",
    "    ngpus=1,\n",
    "    num_channels=1,\n",
    "    latent_dim=100,\n",
    "    alpha=0.2,\n",
    "    post_proc_filt_len=512,\n",
    "    batch_shuffle=False,\n",
    "    verbose=False,\n",
    "    shift_factor=2,\n",
    "    pool_size=50,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    "    lambda_identity=0.5,\n",
    "    batches_per_epoch=10,\n",
    "    lambda_A=10,\n",
    "    lambda_B=10,\n",
    "    no_lsgan=False,\n",
    "    which_direction='AtoB',\n",
    "    lr_policy='lambda',\n",
    "    lr_decay_iters=50,\n",
    "    use_cuda=True,\n",
    "    save_epoch_freq=1,\n",
    ")\n",
    "\n",
    "model_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model = CycleGANModel()\n",
    "model.initialize(opt)\n",
    "#visualizer = Visualizer(opt)\n",
    "total_steps = 0\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for batch_idx in range(opt.batches_per_epoch):\n",
    "        data_A = np_to_input_tensor(next(genA)['X'], use_cuda=opt.use_cuda)\n",
    "        data_B = np_to_input_tensor(next(genB)['X'], use_cuda=opt.use_cuda)  \n",
    "        data = {'A': data_A, 'B': data_B, 'A_paths': [], 'B_paths': []}\n",
    "        \n",
    "        iter_start_time = time.time()\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        #visualizer.reset()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if total_steps % opt.display_freq == 0:\n",
    "            save_result = total_steps % opt.update_html_freq == 0\n",
    "            #visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            #visualizer.print_current_errors(epoch, epoch_iter, errors, t, t_data)\n",
    "            #if opt.display_id > 0:\n",
    "            #    visualizer.plot_current_errors(epoch, float(epoch_iter) / dataset_size, opt, errors)\n",
    "\n",
    "        if total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' %\n",
    "                  (epoch, total_steps))\n",
    "            model.save('latest')\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "              (epoch, total_steps))\n",
    "        model.save('latest')\n",
    "        model.save(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
