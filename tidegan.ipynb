{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import SimpleNamespace\n",
    "import random\n",
    "import librosa\n",
    "import pescador\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2audio(audio_tensor):\n",
    "    audio_numpy = audio_tensor[0].cpu().float().numpy()\n",
    "    return audio_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_audio_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_audibles(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.cpu().state_dict(), save_path)\n",
    "        if len(gpu_ids) and torch.cuda.is_available():\n",
    "            network.cuda(gpu_ids[0])\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        network.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    # update learning rate (called once every epoch)\n",
    "    def update_learning_rate(self):\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate = %.7f' % lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.audio_examples = []\n",
    "\n",
    "    def query(self, audio_examples):\n",
    "        if self.pool_size == 0:\n",
    "            return Variable(audio_examples)\n",
    "        return_audio_examples = []\n",
    "        for audio_data in audio_examples:\n",
    "            audio_data = torch.unsqueeze(audio_data, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.audio_examples.append(audio_data)\n",
    "                return_audio_examples.append(audio_data)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.audio_examples[random_id].clone()\n",
    "                    self.audio_examples[random_id] = audio_data\n",
    "                    return_audio_examples.append(tmp)\n",
    "                else:\n",
    "                    return_audio_examples.append(audio_data)\n",
    "        return_audio_examples = Variable(torch.cat(return_audio_examples, 0))\n",
    "        return return_audio_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scheduler(optimizer, opt):\n",
    "    if opt.lr_policy == 'lambda':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'CycleGANModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        # load/define networks\n",
    "        # The naming conversion is different from those used in the paper\n",
    "        # Code (paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n",
    "        self.netG_A = WaveGANGenerator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                       num_channels=opt.num_channels,\n",
    "                                       latent_dim=opt.latent_dim, alpha=opt.alpha,\n",
    "                                       post_proc_filt_len=opt.post_proc_filt_len, verbose=opt.verbose)\n",
    "        self.netG_B = WaveGANGenerator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                       num_channels=opt.num_channels,\n",
    "                                       latent_dim=opt.latent_dim, alpha=opt.alpha,\n",
    "                                       post_proc_filt_len=opt.post_proc_filt_len, verbose=opt.verbose)\n",
    "\n",
    "        if self.isTrain:\n",
    "            use_sigmoid = opt.no_lsgan\n",
    "            self.netD_A = WaveGANDiscriminator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                               num_channels=opt.num_channels, shift_factor=opt.shift_factor,\n",
    "                                               alpha=opt.alpha, batch_shuffle=opt.batch_shuffle,\n",
    "                                               verbose=opt.verbose)\n",
    "            self.netD_B = WaveGANDiscriminator(model_size=opt.model_size, ngpus=opt.ngpus,\n",
    "                                               num_channels=opt.num_channels, shift_factor=opt.shift_factor,\n",
    "                                               alpha=opt.alpha, batch_shuffle=opt.batch_shuffle,\n",
    "                                               verbose=opt.verbose)\n",
    "            \n",
    "\n",
    "        if self.isTrain:\n",
    "            self.fake_A_pool = AudioPool(opt.pool_size)\n",
    "            self.fake_B_pool = AudioPool(opt.pool_size)\n",
    "            # define loss functions\n",
    "            self.criterionGAN = GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n",
    "            self.criterionCycle = torch.nn.L1Loss()\n",
    "            self.criterionIdt = torch.nn.L1Loss()\n",
    "            # initialize optimizers\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n",
    "                                                lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "            self.optimizers = []\n",
    "            self.schedulers = []\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D_A)\n",
    "            self.optimizers.append(self.optimizer_D_B)\n",
    "            for optimizer in self.optimizers:\n",
    "                self.schedulers.append(get_scheduler(optimizer, opt))\n",
    "\n",
    "        print('---------- Networks initialized -------------')\n",
    "        print_network(self.netG_A)\n",
    "        print_network(self.netG_B)\n",
    "        if self.isTrain:\n",
    "            print_network(self.netD_A)\n",
    "            print_network(self.netD_B)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "    def set_input(self, input):\n",
    "        AtoB = self.opt.which_direction == 'AtoB'\n",
    "        input_A = input['A' if AtoB else 'B']\n",
    "        input_B = input['B' if AtoB else 'A']\n",
    "        if len(self.gpu_ids) > 0:\n",
    "            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n",
    "            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n",
    "        self.input_A = input_A\n",
    "        self.input_B = input_B\n",
    "        self.audio_paths = input['A_paths' if AtoB else 'B_paths']\n",
    "\n",
    "    def forward(self):\n",
    "        self.real_A = Variable(self.input_A)\n",
    "        self.real_B = Variable(self.input_B)\n",
    "\n",
    "    def test(self):\n",
    "        real_A = Variable(self.input_A, volatile=True)\n",
    "        fake_B = self.netG_A(real_A)\n",
    "        self.rec_A = self.netG_B(fake_B).data\n",
    "        self.fake_B = fake_B.data\n",
    "\n",
    "        real_B = Variable(self.input_B, volatile=True)\n",
    "        fake_A = self.netG_B(real_B)\n",
    "        self.rec_B = self.netG_A(fake_A).data\n",
    "        self.fake_A = fake_A.data\n",
    "\n",
    "    # get audio paths\n",
    "    def get_audio_paths(self):\n",
    "        return self.audio_paths\n",
    "\n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        # backward\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "\n",
    "    def backward_D_A(self):\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "        self.loss_D_A = loss_D_A.data[0]\n",
    "\n",
    "    def backward_D_B(self):\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "        self.loss_D_B = loss_D_B.data[0]\n",
    "\n",
    "    def backward_G(self):\n",
    "        lambda_idt = self.opt.lambda_identity\n",
    "        lambda_A = self.opt.lambda_A\n",
    "        lambda_B = self.opt.lambda_B\n",
    "        # Identity loss\n",
    "        if lambda_idt > 0:\n",
    "            # G_A should be identity if real_B is fed.\n",
    "            idt_A = self.netG_A(self.real_B)\n",
    "            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # G_B should be identity if real_A is fed.\n",
    "            idt_B = self.netG_B(self.real_A)\n",
    "            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "\n",
    "            self.idt_A = idt_A.data\n",
    "            self.idt_B = idt_B.data\n",
    "            self.loss_idt_A = loss_idt_A.data[0]\n",
    "            self.loss_idt_B = loss_idt_B.data[0]\n",
    "        else:\n",
    "            loss_idt_A = 0\n",
    "            loss_idt_B = 0\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        fake_B = self.netG_A(self.real_A)\n",
    "        pred_fake = self.netD_A(fake_B)\n",
    "        loss_G_A = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        fake_A = self.netG_B(self.real_B)\n",
    "        pred_fake = self.netD_B(fake_A)\n",
    "        loss_G_B = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # Forward cycle loss\n",
    "        rec_A = self.netG_B(fake_B)\n",
    "        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n",
    "\n",
    "        # Backward cycle loss\n",
    "        rec_B = self.netG_A(fake_A)\n",
    "        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n",
    "        # combined loss\n",
    "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n",
    "        loss_G.backward()\n",
    "\n",
    "        self.fake_B = fake_B.data\n",
    "        self.fake_A = fake_A.data\n",
    "        self.rec_A = rec_A.data\n",
    "        self.rec_B = rec_B.data\n",
    "\n",
    "        self.loss_G_A = loss_G_A.data[0]\n",
    "        self.loss_G_B = loss_G_B.data[0]\n",
    "        self.loss_cycle_A = loss_cycle_A.data[0]\n",
    "        self.loss_cycle_B = loss_cycle_B.data[0]\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        # forward\n",
    "        self.forward()\n",
    "        # G_A and G_B\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "        # D_A\n",
    "        self.optimizer_D_A.zero_grad()\n",
    "        self.backward_D_A()\n",
    "        self.optimizer_D_A.step()\n",
    "        # D_B\n",
    "        self.optimizer_D_B.zero_grad()\n",
    "        self.backward_D_B()\n",
    "        self.optimizer_D_B.step()\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n",
    "                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n",
    "        if self.opt.lambda_identity > 0.0:\n",
    "            ret_errors['idt_A'] = self.loss_idt_A\n",
    "            ret_errors['idt_B'] = self.loss_idt_B\n",
    "        return ret_errors\n",
    "\n",
    "    def get_current_audibles(self):\n",
    "        real_A = tensor2audio(self.input_A)\n",
    "        fake_B = tensor2audio(self.fake_B)\n",
    "        rec_A = tensor2audio(self.rec_A)\n",
    "        real_B = tensor2audio(self.input_B)\n",
    "        fake_A = tensor2audio(self.fake_A)\n",
    "        rec_B = tensor2audio(self.rec_B)\n",
    "        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n",
    "                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n",
    "        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n",
    "            ret_visuals['idt_A'] = tensor2audio(self.idt_A)\n",
    "            ret_visuals['idt_B'] = tensor2audio(self.idt_B)\n",
    "        return ret_visuals\n",
    "\n",
    "    def save(self, label):\n",
    "        self.save_network(self.netG_A, 'G_A', label, self.gpu_ids)\n",
    "        self.save_network(self.netD_A, 'D_A', label, self.gpu_ids)\n",
    "        self.save_network(self.netG_B, 'G_B', label, self.gpu_ids)\n",
    "        self.save_network(self.netD_B, 'D_B', label, self.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the GAN loss which uses either LSGAN or the regular GAN.\n",
    "# When LSGAN is used, it is basically same as MSELoss,\n",
    "# but it abstracts away the need to create the target label tensor\n",
    "# that has the same size as the input\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n",
    "                 tensor=torch.FloatTensor):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = target_real_label\n",
    "        self.fake_label = target_fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.Tensor = tensor\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or\n",
    "                            (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or\n",
    "                            (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGANGenerator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, latent_dim=100, alpha=0.2,\n",
    "                 post_proc_filt_len=512, verbose=False):\n",
    "        super(WaveGANGenerator, self).__init__()\n",
    "        self.ngpus = ngpus\n",
    "        self.model_size = model_size # d\n",
    "        self.num_channels = num_channels # c\n",
    "        self.latent_dim = latent_dim\n",
    "        self.post_proc_filt_len = post_proc_filt_len\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, latent_dim))\n",
    "        self.fc2 = nn.DataParallel(nn.Linear(latent_dim, 256 * model_size))\n",
    "\n",
    "        self.tconv1 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(16 * model_size, 8 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv2 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(8 * model_size, 4 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv3 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(4 * model_size, 2 * model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv4 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(2 * model_size, model_size, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "        self.tconv5 = nn.DataParallel(\n",
    "            nn.ConvTranspose1d(model_size, num_channels, 25, stride=4, padding=11,\n",
    "                               output_padding=1))\n",
    "\n",
    "        if post_proc_filt_len:\n",
    "            self.ppfilter1 = nn.DataParallel(nn.Conv1d(num_channels, num_channels, post_proc_filt_len))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x)).view(-1, 16 * self.model_size, 16)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv3(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = F.relu(self.tconv4(x))\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        output = F.tanh(self.tconv5(x))\n",
    "        if self.verbose:\n",
    "            print(output.shape)\n",
    "\n",
    "        if self.post_proc_filt_len:\n",
    "            # Pad for \"same\" filtering\n",
    "            if (self.post_proc_filt_len % 2) == 0:\n",
    "                pad_left = self.post_proc_filt_len // 2\n",
    "                pad_right = pad_left - 1\n",
    "            else:\n",
    "                pad_left = (self.post_proc_filt_len - 1) // 2\n",
    "                pad_right = pad_left\n",
    "            output = self.ppfilter1(F.pad(output, (pad_left, pad_right)))\n",
    "            if self.verbose:\n",
    "                print(output.shape)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs phase shuffling, i.e. shifting feature axis of a 3D tensor\n",
    "    by a random integer in {-n, n} and performing reflection padding where\n",
    "    necessary\n",
    "    \"\"\"\n",
    "    def __init__(self, n, batch_shuffle=True):\n",
    "        super(PhaseShuffle, self).__init__()\n",
    "        self.n = n\n",
    "        self.batch_shuffle = batch_shuffle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Make sure to use PyTorch to generate number RNG state is all shared\n",
    "        if self.batch_shuffle:                                                              \n",
    "            # Make sure to use PyTorcTrueh to generate number RNG state is all shared       \n",
    "            k = int(torch.Tensor(1).random_(0, 2*self.n + 1)) - self.n\n",
    "\n",
    "            # Return if no phase shift                                                      \n",
    "            if k == 0:                                                                      \n",
    "                return x                                                                    \n",
    "\n",
    "            # Slice feature dimension                                                       \n",
    "            if k > 0:                                                                       \n",
    "                x_trunc = x[:, :, :-k]                                                      \n",
    "                pad = (k, 0)                                                                \n",
    "            else:                                                                           \n",
    "                x_trunc = x[:, :, -k:]                                                      \n",
    "                pad = (0, -k)                                                               \n",
    "\n",
    "            # Reflection padding                                                            \n",
    "            x_shuffle = F.pad(x_trunc, pad, mode='reflect')                                 \n",
    "\n",
    "        else:                                                                               \n",
    "            k_list = torch.Tensor(x.shape[0]).random_(0, 2*self.n+1) - self.n                                                         \n",
    "            k_list = k_list.numpy().astype(int)                                             \n",
    "            x_shuffle = x.clone()                                                           \n",
    "\n",
    "            for idx, k in enumerate(k_list):                                                \n",
    "                k = int(k)                                                                  \n",
    "                if k > 0:                                                                   \n",
    "                    xi_trunc = x[idx:idx+1, :, :-k]                                         \n",
    "                    pad = (k, 0)                                                            \n",
    "                else:                                                                       \n",
    "                    xi_trunc = x[idx:idx+1, :, -k:]                                         \n",
    "                    pad = (0, -k)                                                           \n",
    "\n",
    "                x_shuffle[idx:idx+1] = F.pad(xi_trunc, pad, mode='reflect')                 \n",
    "\n",
    "\n",
    "        assert x_shuffle.shape == x.shape, \"{}, {}\".format(x_shuffle.shape, x.shape)\n",
    "        return x_shuffle\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGANDiscriminator(nn.Module):\n",
    "    def __init__(self, model_size=64, ngpus=1, num_channels=1, shift_factor=2, alpha=0.2, batch_shuffle=False, verbose=False):\n",
    "        super(WaveGANDiscriminator, self).__init__()\n",
    "        self.model_size = model_size # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels # c\n",
    "        self.shift_factor = shift_factor # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, etc.)\n",
    "        self.conv1 = nn.DataParallel(nn.Conv1d(num_channels, model_size, 25, stride=4, padding=11))\n",
    "        self.conv2 = nn.DataParallel(\n",
    "            nn.Conv1d(model_size, 2 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv3 = nn.DataParallel(\n",
    "            nn.Conv1d(2 * model_size, 4 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv4 = nn.DataParallel(\n",
    "            nn.Conv1d(4 * model_size, 8 * model_size, 25, stride=4, padding=11))\n",
    "        self.conv5 = nn.DataParallel(\n",
    "            nn.Conv1d(8 * model_size, 16 * model_size, 25, stride=4, padding=11))\n",
    "        self.ps1 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps2 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps3 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.ps4 = PhaseShuffle(shift_factor, batch_shuffle=batch_shuffle)\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(256 * model_size, 1))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        x = self.ps4(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 256 * self.model_size)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        return F.sigmoid(self.fc1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sample_generator(filepath, window_length=16384, fs=16000):\n",
    "    \"\"\"\n",
    "    Audio sample generator\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(filepath, sr=fs)\n",
    "    except Exception as e:\n",
    "        raise StopIteration()\n",
    "        \n",
    "    audio_len = len(audio_data)\n",
    "    \n",
    "    # Pad audio to at least a single frame\n",
    "    if audio_len < window_length:\n",
    "        pad_length = window_length - audio_len\n",
    "        left_pad = pad_length // 2\n",
    "        right_pad = pad_length - left_pad\n",
    "        \n",
    "        audio_data = np.pad(audio_data, (left_pad, right_pad), mode='constant')\n",
    "        audio_len = len(audio_data)\n",
    "        \n",
    "    while True:\n",
    "        if audio_len == window_length:\n",
    "            # If we only have a single frame's worth of audio, just yield the whole audio\n",
    "            sample = audio_data\n",
    "        else:\n",
    "            # Sample a random window from the audio file\n",
    "            start_idx = np.random.randint(0,audio_len - window_length)\n",
    "            end_idx = start_idx + window_length\n",
    "            sample = audio_data[start_idx:end_idx]\n",
    "            \n",
    "        sample = sample.astype('float32')\n",
    "        assert not np.any(np.isnan(sample))\n",
    "            \n",
    "        yield {'X': sample}\n",
    "    \n",
    "def create_batch_generator(audio_filepath_list, batch_size):\n",
    "    streamers = []\n",
    "    for audio_filepath in audio_filepath_list:\n",
    "        s = pescador.Streamer(file_sample_generator, audio_filepath)\n",
    "        streamers.append(s)\n",
    "        \n",
    "    mux = pescador.ShuffledMux(streamers)\n",
    "    batch_gen = pescador.buffer_stream(mux, batch_size)\n",
    "    \n",
    "    return batch_gen\n",
    "\n",
    "def get_all_audio_filepaths(audio_dir):\n",
    "    return [os.path.join(root, fname)\n",
    "            for (root, dir_names, file_names) in os.walk(audio_dir)\n",
    "            for fname in file_names\n",
    "            if fname.lower().endswith('.wav')]\n",
    "\n",
    "def create_data_split(audio_filepath_list, valid_ratio, test_ratio, train_batch_size, valid_size, test_size):\n",
    "    num_files = len(audio_filepath_list)\n",
    "    num_valid = int(np.ceil(num_files * valid_ratio))\n",
    "    num_test = int(np.ceil(num_files * test_ratio))\n",
    "    num_train = num_files - num_valid - num_test\n",
    "    \n",
    "    assert num_valid > 0\n",
    "    assert num_test > 0\n",
    "    assert num_train > 0\n",
    "    \n",
    "    valid_files = audio_filepath_list[:num_valid]\n",
    "    test_files = audio_filepath_list[num_valid:num_valid+num_test]\n",
    "    train_files = audio_filepath_list[num_valid+num_test:]\n",
    "    \n",
    "    train_gen = create_batch_generator(train_files, train_batch_size)\n",
    "    valid_data = next(iter(create_batch_generator(valid_files, valid_size)))\n",
    "    test_data = next(iter(create_batch_generator(train_files, test_size)))\n",
    "    \n",
    "    return train_gen, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_input_tensor(data, use_cuda):\n",
    "    data = data[:,np.newaxis,:]\n",
    "    data = torch.Tensor(data)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "audio_dir_A = \"/beegfs/jtc440/aml/TheDrumClub-Kit004-THEMEGABUNDLE/Rhodes Polaris\"\n",
    "audio_filepaths_A = get_all_audio_filepaths(audio_dir_A)\n",
    "genA, valid_data_A, test_data_A = create_data_split(audio_filepaths_A, 0.1, 0.1, batch_size, 64, 64)\n",
    "\n",
    "audio_dir_B = \"/beegfs/jtc440/aml/TheDrumClub-Kit004-THEMEGABUNDLE/Korg M1\"\n",
    "audio_filepaths_B = get_all_audio_filepaths(audio_dir_B)\n",
    "genB, valid_data_B, test_data_B = create_data_split(audio_filepaths_B, 0.1, 0.1, batch_size, 64, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tidegan_samples(output_dir, current_audibles, step, fs=16000):\n",
    "    samples_dir = os.path.join(output_dir, 'samples', str(step))\n",
    "    if not os.path.exists(samples_dir):\n",
    "        os.makedirs(samples_dir)\n",
    "        \n",
    "    for out_type, data in current_audibles.items():\n",
    "        for idx, sample in enumerate(data):\n",
    "            output_path = os.path.join(samples_dir, \"{}_{}.wav\".format(out_type, idx+1))\n",
    "            librosa.output.write_wav(output_path, sample, sr=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "WaveGANGenerator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=100, bias=True)\n",
      "  )\n",
      "  (fc2): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (tconv1): DataParallel(\n",
      "    (module): ConvTranspose1d(1024, 512, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv2): DataParallel(\n",
      "    (module): ConvTranspose1d(512, 256, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv3): DataParallel(\n",
      "    (module): ConvTranspose1d(256, 128, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv4): DataParallel(\n",
      "    (module): ConvTranspose1d(128, 64, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv5): DataParallel(\n",
      "    (module): ConvTranspose1d(64, 1, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 38115942\n",
      "WaveGANGenerator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=100, bias=True)\n",
      "  )\n",
      "  (fc2): DataParallel(\n",
      "    (module): Linear(in_features=100, out_features=16384, bias=True)\n",
      "  )\n",
      "  (tconv1): DataParallel(\n",
      "    (module): ConvTranspose1d(1024, 512, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv2): DataParallel(\n",
      "    (module): ConvTranspose1d(512, 256, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv3): DataParallel(\n",
      "    (module): ConvTranspose1d(256, 128, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv4): DataParallel(\n",
      "    (module): ConvTranspose1d(128, 64, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (tconv5): DataParallel(\n",
      "    (module): ConvTranspose1d(64, 1, kernel_size=(25,), stride=(4,), padding=(11,), output_padding=(1,))\n",
      "  )\n",
      "  (ppfilter1): DataParallel(\n",
      "    (module): Conv1d(1, 1, kernel_size=(512,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 38115942\n",
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 17427969\n",
      "WaveGANDiscriminator(\n",
      "  (conv1): DataParallel(\n",
      "    (module): Conv1d(1, 64, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv2): DataParallel(\n",
      "    (module): Conv1d(64, 128, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv3): DataParallel(\n",
      "    (module): Conv1d(128, 256, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv4): DataParallel(\n",
      "    (module): Conv1d(256, 512, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (conv5): DataParallel(\n",
      "    (module): Conv1d(512, 1024, kernel_size=(25,), stride=(4,), padding=(11,))\n",
      "  )\n",
      "  (ps1): PhaseShuffle(\n",
      "  )\n",
      "  (ps2): PhaseShuffle(\n",
      "  )\n",
      "  (ps3): PhaseShuffle(\n",
      "  )\n",
      "  (ps4): PhaseShuffle(\n",
      "  )\n",
      "  (fc1): DataParallel(\n",
      "    (module): Linear(in_features=16384, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 17427969\n",
      "-----------------------------------------------\n",
      "saving the latest model (epoch 0, total_steps 64)\n",
      "saving the latest model (epoch 0, total_steps 128)\n",
      "saving the latest model (epoch 0, total_steps 192)\n",
      "saving the latest model (epoch 0, total_steps 256)\n",
      "saving the latest model (epoch 0, total_steps 320)\n",
      "saving the latest model (epoch 0, total_steps 384)\n",
      "saving the latest model (epoch 0, total_steps 448)\n",
      "saving the latest model (epoch 0, total_steps 512)\n",
      "saving the latest model (epoch 0, total_steps 576)\n",
      "saving the latest model (epoch 0, total_steps 640)\n",
      "saving the model at the end of epoch 0, iters 640\n",
      "End of epoch 0 / 50 \t Time Taken: 57 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 1, total_steps 704)\n",
      "saving the latest model (epoch 1, total_steps 768)\n",
      "saving the latest model (epoch 1, total_steps 832)\n",
      "saving the latest model (epoch 1, total_steps 896)\n",
      "saving the latest model (epoch 1, total_steps 960)\n",
      "saving the latest model (epoch 1, total_steps 1024)\n",
      "saving the latest model (epoch 1, total_steps 1088)\n",
      "saving the latest model (epoch 1, total_steps 1152)\n",
      "saving the latest model (epoch 1, total_steps 1216)\n",
      "saving the latest model (epoch 1, total_steps 1280)\n",
      "saving the model at the end of epoch 1, iters 1280\n",
      "End of epoch 1 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 2, total_steps 1344)\n",
      "saving the latest model (epoch 2, total_steps 1408)\n",
      "saving the latest model (epoch 2, total_steps 1472)\n",
      "saving the latest model (epoch 2, total_steps 1536)\n",
      "saving the latest model (epoch 2, total_steps 1600)\n",
      "saving the latest model (epoch 2, total_steps 1664)\n",
      "saving the latest model (epoch 2, total_steps 1728)\n",
      "saving the latest model (epoch 2, total_steps 1792)\n",
      "saving the latest model (epoch 2, total_steps 1856)\n",
      "saving the latest model (epoch 2, total_steps 1920)\n",
      "saving the model at the end of epoch 2, iters 1920\n",
      "End of epoch 2 / 50 \t Time Taken: 57 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 3, total_steps 1984)\n",
      "saving the latest model (epoch 3, total_steps 2048)\n",
      "saving the latest model (epoch 3, total_steps 2112)\n",
      "saving the latest model (epoch 3, total_steps 2176)\n",
      "saving the latest model (epoch 3, total_steps 2240)\n",
      "saving the latest model (epoch 3, total_steps 2304)\n",
      "saving the latest model (epoch 3, total_steps 2368)\n",
      "saving the latest model (epoch 3, total_steps 2432)\n",
      "saving the latest model (epoch 3, total_steps 2496)\n",
      "saving the latest model (epoch 3, total_steps 2560)\n",
      "saving the model at the end of epoch 3, iters 2560\n",
      "End of epoch 3 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 4, total_steps 2624)\n",
      "saving the latest model (epoch 4, total_steps 2688)\n",
      "saving the latest model (epoch 4, total_steps 2752)\n",
      "saving the latest model (epoch 4, total_steps 2816)\n",
      "saving the latest model (epoch 4, total_steps 2880)\n",
      "saving the latest model (epoch 4, total_steps 2944)\n",
      "saving the latest model (epoch 4, total_steps 3008)\n",
      "saving the latest model (epoch 4, total_steps 3072)\n",
      "saving the latest model (epoch 4, total_steps 3136)\n",
      "saving the latest model (epoch 4, total_steps 3200)\n",
      "saving the model at the end of epoch 4, iters 3200\n",
      "End of epoch 4 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 5, total_steps 3264)\n",
      "saving the latest model (epoch 5, total_steps 3328)\n",
      "saving the latest model (epoch 5, total_steps 3392)\n",
      "saving the latest model (epoch 5, total_steps 3456)\n",
      "saving the latest model (epoch 5, total_steps 3520)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the latest model (epoch 5, total_steps 3584)\n",
      "saving the latest model (epoch 5, total_steps 3648)\n",
      "saving the latest model (epoch 5, total_steps 3712)\n",
      "saving the latest model (epoch 5, total_steps 3776)\n",
      "saving the latest model (epoch 5, total_steps 3840)\n",
      "saving the model at the end of epoch 5, iters 3840\n",
      "End of epoch 5 / 50 \t Time Taken: 57 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 6, total_steps 3904)\n",
      "saving the latest model (epoch 6, total_steps 3968)\n",
      "saving the latest model (epoch 6, total_steps 4032)\n",
      "saving the latest model (epoch 6, total_steps 4096)\n",
      "saving the latest model (epoch 6, total_steps 4160)\n",
      "saving the latest model (epoch 6, total_steps 4224)\n",
      "saving the latest model (epoch 6, total_steps 4288)\n",
      "saving the latest model (epoch 6, total_steps 4352)\n",
      "saving the latest model (epoch 6, total_steps 4416)\n",
      "saving the latest model (epoch 6, total_steps 4480)\n",
      "saving the model at the end of epoch 6, iters 4480\n",
      "End of epoch 6 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 7, total_steps 4544)\n",
      "saving the latest model (epoch 7, total_steps 4608)\n",
      "saving the latest model (epoch 7, total_steps 4672)\n",
      "saving the latest model (epoch 7, total_steps 4736)\n",
      "saving the latest model (epoch 7, total_steps 4800)\n",
      "saving the latest model (epoch 7, total_steps 4864)\n",
      "saving the latest model (epoch 7, total_steps 4928)\n",
      "saving the latest model (epoch 7, total_steps 4992)\n",
      "saving the latest model (epoch 7, total_steps 5056)\n",
      "saving the latest model (epoch 7, total_steps 5120)\n",
      "saving the model at the end of epoch 7, iters 5120\n",
      "End of epoch 7 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 8, total_steps 5184)\n",
      "saving the latest model (epoch 8, total_steps 5248)\n",
      "saving the latest model (epoch 8, total_steps 5312)\n",
      "saving the latest model (epoch 8, total_steps 5376)\n",
      "saving the latest model (epoch 8, total_steps 5440)\n",
      "saving the latest model (epoch 8, total_steps 5504)\n",
      "saving the latest model (epoch 8, total_steps 5568)\n",
      "saving the latest model (epoch 8, total_steps 5632)\n",
      "saving the latest model (epoch 8, total_steps 5696)\n",
      "saving the latest model (epoch 8, total_steps 5760)\n",
      "saving the model at the end of epoch 8, iters 5760\n",
      "End of epoch 8 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 9, total_steps 5824)\n",
      "saving the latest model (epoch 9, total_steps 5888)\n",
      "saving the latest model (epoch 9, total_steps 5952)\n",
      "saving the latest model (epoch 9, total_steps 6016)\n",
      "saving the latest model (epoch 9, total_steps 6080)\n",
      "saving the latest model (epoch 9, total_steps 6144)\n",
      "saving the latest model (epoch 9, total_steps 6208)\n",
      "saving the latest model (epoch 9, total_steps 6272)\n",
      "saving the latest model (epoch 9, total_steps 6336)\n",
      "saving the latest model (epoch 9, total_steps 6400)\n",
      "saving the model at the end of epoch 9, iters 6400\n",
      "End of epoch 9 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 10, total_steps 6464)\n",
      "saving the latest model (epoch 10, total_steps 6528)\n",
      "saving the latest model (epoch 10, total_steps 6592)\n",
      "saving the latest model (epoch 10, total_steps 6656)\n",
      "saving the latest model (epoch 10, total_steps 6720)\n",
      "saving the latest model (epoch 10, total_steps 6784)\n",
      "saving the latest model (epoch 10, total_steps 6848)\n",
      "saving the latest model (epoch 10, total_steps 6912)\n",
      "saving the latest model (epoch 10, total_steps 6976)\n",
      "saving the latest model (epoch 10, total_steps 7040)\n",
      "saving the model at the end of epoch 10, iters 7040\n",
      "End of epoch 10 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 11, total_steps 7104)\n",
      "saving the latest model (epoch 11, total_steps 7168)\n",
      "saving the latest model (epoch 11, total_steps 7232)\n",
      "saving the latest model (epoch 11, total_steps 7296)\n",
      "saving the latest model (epoch 11, total_steps 7360)\n",
      "saving the latest model (epoch 11, total_steps 7424)\n",
      "saving the latest model (epoch 11, total_steps 7488)\n",
      "saving the latest model (epoch 11, total_steps 7552)\n",
      "saving the latest model (epoch 11, total_steps 7616)\n",
      "saving the latest model (epoch 11, total_steps 7680)\n",
      "saving the model at the end of epoch 11, iters 7680\n",
      "End of epoch 11 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 12, total_steps 7744)\n",
      "saving the latest model (epoch 12, total_steps 7808)\n",
      "saving the latest model (epoch 12, total_steps 7872)\n",
      "saving the latest model (epoch 12, total_steps 7936)\n",
      "saving the latest model (epoch 12, total_steps 8000)\n",
      "saving the latest model (epoch 12, total_steps 8064)\n",
      "saving the latest model (epoch 12, total_steps 8128)\n",
      "saving the latest model (epoch 12, total_steps 8192)\n",
      "saving the latest model (epoch 12, total_steps 8256)\n",
      "saving the latest model (epoch 12, total_steps 8320)\n",
      "saving the model at the end of epoch 12, iters 8320\n",
      "End of epoch 12 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 13, total_steps 8384)\n",
      "saving the latest model (epoch 13, total_steps 8448)\n",
      "saving the latest model (epoch 13, total_steps 8512)\n",
      "saving the latest model (epoch 13, total_steps 8576)\n",
      "saving the latest model (epoch 13, total_steps 8640)\n",
      "saving the latest model (epoch 13, total_steps 8704)\n",
      "saving the latest model (epoch 13, total_steps 8768)\n",
      "saving the latest model (epoch 13, total_steps 8832)\n",
      "saving the latest model (epoch 13, total_steps 8896)\n",
      "saving the latest model (epoch 13, total_steps 8960)\n",
      "saving the model at the end of epoch 13, iters 8960\n",
      "End of epoch 13 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 14, total_steps 9024)\n",
      "saving the latest model (epoch 14, total_steps 9088)\n",
      "saving the latest model (epoch 14, total_steps 9152)\n",
      "saving the latest model (epoch 14, total_steps 9216)\n",
      "saving the latest model (epoch 14, total_steps 9280)\n",
      "saving the latest model (epoch 14, total_steps 9344)\n",
      "saving the latest model (epoch 14, total_steps 9408)\n",
      "saving the latest model (epoch 14, total_steps 9472)\n",
      "saving the latest model (epoch 14, total_steps 9536)\n",
      "saving the latest model (epoch 14, total_steps 9600)\n",
      "saving the model at the end of epoch 14, iters 9600\n",
      "End of epoch 14 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 15, total_steps 9664)\n",
      "saving the latest model (epoch 15, total_steps 9728)\n",
      "saving the latest model (epoch 15, total_steps 9792)\n",
      "saving the latest model (epoch 15, total_steps 9856)\n",
      "saving the latest model (epoch 15, total_steps 9920)\n",
      "saving the latest model (epoch 15, total_steps 9984)\n",
      "saving the latest model (epoch 15, total_steps 10048)\n",
      "saving the latest model (epoch 15, total_steps 10112)\n",
      "saving the latest model (epoch 15, total_steps 10176)\n",
      "saving the latest model (epoch 15, total_steps 10240)\n",
      "saving the model at the end of epoch 15, iters 10240\n",
      "End of epoch 15 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 16, total_steps 10304)\n",
      "saving the latest model (epoch 16, total_steps 10368)\n",
      "saving the latest model (epoch 16, total_steps 10432)\n",
      "saving the latest model (epoch 16, total_steps 10496)\n",
      "saving the latest model (epoch 16, total_steps 10560)\n",
      "saving the latest model (epoch 16, total_steps 10624)\n",
      "saving the latest model (epoch 16, total_steps 10688)\n",
      "saving the latest model (epoch 16, total_steps 10752)\n",
      "saving the latest model (epoch 16, total_steps 10816)\n",
      "saving the latest model (epoch 16, total_steps 10880)\n",
      "saving the model at the end of epoch 16, iters 10880\n",
      "End of epoch 16 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 17, total_steps 10944)\n",
      "saving the latest model (epoch 17, total_steps 11008)\n",
      "saving the latest model (epoch 17, total_steps 11072)\n",
      "saving the latest model (epoch 17, total_steps 11136)\n",
      "saving the latest model (epoch 17, total_steps 11200)\n",
      "saving the latest model (epoch 17, total_steps 11264)\n",
      "saving the latest model (epoch 17, total_steps 11328)\n",
      "saving the latest model (epoch 17, total_steps 11392)\n",
      "saving the latest model (epoch 17, total_steps 11456)\n",
      "saving the latest model (epoch 17, total_steps 11520)\n",
      "saving the model at the end of epoch 17, iters 11520\n",
      "End of epoch 17 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 18, total_steps 11584)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the latest model (epoch 18, total_steps 11648)\n",
      "saving the latest model (epoch 18, total_steps 11712)\n",
      "saving the latest model (epoch 18, total_steps 11776)\n",
      "saving the latest model (epoch 18, total_steps 11840)\n",
      "saving the latest model (epoch 18, total_steps 11904)\n",
      "saving the latest model (epoch 18, total_steps 11968)\n",
      "saving the latest model (epoch 18, total_steps 12032)\n",
      "saving the latest model (epoch 18, total_steps 12096)\n",
      "saving the latest model (epoch 18, total_steps 12160)\n",
      "saving the model at the end of epoch 18, iters 12160\n",
      "End of epoch 18 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 19, total_steps 12224)\n",
      "saving the latest model (epoch 19, total_steps 12288)\n",
      "saving the latest model (epoch 19, total_steps 12352)\n",
      "saving the latest model (epoch 19, total_steps 12416)\n",
      "saving the latest model (epoch 19, total_steps 12480)\n",
      "saving the latest model (epoch 19, total_steps 12544)\n",
      "saving the latest model (epoch 19, total_steps 12608)\n",
      "saving the latest model (epoch 19, total_steps 12672)\n",
      "saving the latest model (epoch 19, total_steps 12736)\n",
      "saving the latest model (epoch 19, total_steps 12800)\n",
      "saving the model at the end of epoch 19, iters 12800\n",
      "End of epoch 19 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 20, total_steps 12864)\n",
      "saving the latest model (epoch 20, total_steps 12928)\n",
      "saving the latest model (epoch 20, total_steps 12992)\n",
      "saving the latest model (epoch 20, total_steps 13056)\n",
      "saving the latest model (epoch 20, total_steps 13120)\n",
      "saving the latest model (epoch 20, total_steps 13184)\n",
      "saving the latest model (epoch 20, total_steps 13248)\n",
      "saving the latest model (epoch 20, total_steps 13312)\n",
      "saving the latest model (epoch 20, total_steps 13376)\n",
      "saving the latest model (epoch 20, total_steps 13440)\n",
      "saving the model at the end of epoch 20, iters 13440\n",
      "End of epoch 20 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 21, total_steps 13504)\n",
      "saving the latest model (epoch 21, total_steps 13568)\n",
      "saving the latest model (epoch 21, total_steps 13632)\n",
      "saving the latest model (epoch 21, total_steps 13696)\n",
      "saving the latest model (epoch 21, total_steps 13760)\n",
      "saving the latest model (epoch 21, total_steps 13824)\n",
      "saving the latest model (epoch 21, total_steps 13888)\n",
      "saving the latest model (epoch 21, total_steps 13952)\n",
      "saving the latest model (epoch 21, total_steps 14016)\n",
      "saving the latest model (epoch 21, total_steps 14080)\n",
      "saving the model at the end of epoch 21, iters 14080\n",
      "End of epoch 21 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 22, total_steps 14144)\n",
      "saving the latest model (epoch 22, total_steps 14208)\n",
      "saving the latest model (epoch 22, total_steps 14272)\n",
      "saving the latest model (epoch 22, total_steps 14336)\n",
      "saving the latest model (epoch 22, total_steps 14400)\n",
      "saving the latest model (epoch 22, total_steps 14464)\n",
      "saving the latest model (epoch 22, total_steps 14528)\n",
      "saving the latest model (epoch 22, total_steps 14592)\n",
      "saving the latest model (epoch 22, total_steps 14656)\n",
      "saving the latest model (epoch 22, total_steps 14720)\n",
      "saving the model at the end of epoch 22, iters 14720\n",
      "End of epoch 22 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 23, total_steps 14784)\n",
      "saving the latest model (epoch 23, total_steps 14848)\n",
      "saving the latest model (epoch 23, total_steps 14912)\n",
      "saving the latest model (epoch 23, total_steps 14976)\n",
      "saving the latest model (epoch 23, total_steps 15040)\n",
      "saving the latest model (epoch 23, total_steps 15104)\n",
      "saving the latest model (epoch 23, total_steps 15168)\n",
      "saving the latest model (epoch 23, total_steps 15232)\n",
      "saving the latest model (epoch 23, total_steps 15296)\n",
      "saving the latest model (epoch 23, total_steps 15360)\n",
      "saving the model at the end of epoch 23, iters 15360\n",
      "End of epoch 23 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 24, total_steps 15424)\n",
      "saving the latest model (epoch 24, total_steps 15488)\n",
      "saving the latest model (epoch 24, total_steps 15552)\n",
      "saving the latest model (epoch 24, total_steps 15616)\n",
      "saving the latest model (epoch 24, total_steps 15680)\n",
      "saving the latest model (epoch 24, total_steps 15744)\n",
      "saving the latest model (epoch 24, total_steps 15808)\n",
      "saving the latest model (epoch 24, total_steps 15872)\n",
      "saving the latest model (epoch 24, total_steps 15936)\n",
      "saving the latest model (epoch 24, total_steps 16000)\n",
      "saving the model at the end of epoch 24, iters 16000\n",
      "End of epoch 24 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 25, total_steps 16064)\n",
      "saving the latest model (epoch 25, total_steps 16128)\n",
      "saving the latest model (epoch 25, total_steps 16192)\n",
      "saving the latest model (epoch 25, total_steps 16256)\n",
      "saving the latest model (epoch 25, total_steps 16320)\n",
      "saving the latest model (epoch 25, total_steps 16384)\n",
      "saving the latest model (epoch 25, total_steps 16448)\n",
      "saving the latest model (epoch 25, total_steps 16512)\n",
      "saving the latest model (epoch 25, total_steps 16576)\n",
      "saving the latest model (epoch 25, total_steps 16640)\n",
      "saving the model at the end of epoch 25, iters 16640\n",
      "End of epoch 25 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 26, total_steps 16704)\n",
      "saving the latest model (epoch 26, total_steps 16768)\n",
      "saving the latest model (epoch 26, total_steps 16832)\n",
      "saving the latest model (epoch 26, total_steps 16896)\n",
      "saving the latest model (epoch 26, total_steps 16960)\n",
      "saving the latest model (epoch 26, total_steps 17024)\n",
      "saving the latest model (epoch 26, total_steps 17088)\n",
      "saving the latest model (epoch 26, total_steps 17152)\n",
      "saving the latest model (epoch 26, total_steps 17216)\n",
      "saving the latest model (epoch 26, total_steps 17280)\n",
      "saving the model at the end of epoch 26, iters 17280\n",
      "End of epoch 26 / 50 \t Time Taken: 57 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 27, total_steps 17344)\n",
      "saving the latest model (epoch 27, total_steps 17408)\n",
      "saving the latest model (epoch 27, total_steps 17472)\n",
      "saving the latest model (epoch 27, total_steps 17536)\n",
      "saving the latest model (epoch 27, total_steps 17600)\n",
      "saving the latest model (epoch 27, total_steps 17664)\n",
      "saving the latest model (epoch 27, total_steps 17728)\n",
      "saving the latest model (epoch 27, total_steps 17792)\n",
      "saving the latest model (epoch 27, total_steps 17856)\n",
      "saving the latest model (epoch 27, total_steps 17920)\n",
      "saving the model at the end of epoch 27, iters 17920\n",
      "End of epoch 27 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 28, total_steps 17984)\n",
      "saving the latest model (epoch 28, total_steps 18048)\n",
      "saving the latest model (epoch 28, total_steps 18112)\n",
      "saving the latest model (epoch 28, total_steps 18176)\n",
      "saving the latest model (epoch 28, total_steps 18240)\n",
      "saving the latest model (epoch 28, total_steps 18304)\n",
      "saving the latest model (epoch 28, total_steps 18368)\n",
      "saving the latest model (epoch 28, total_steps 18432)\n",
      "saving the latest model (epoch 28, total_steps 18496)\n",
      "saving the latest model (epoch 28, total_steps 18560)\n",
      "saving the model at the end of epoch 28, iters 18560\n",
      "End of epoch 28 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 29, total_steps 18624)\n",
      "saving the latest model (epoch 29, total_steps 18688)\n",
      "saving the latest model (epoch 29, total_steps 18752)\n",
      "saving the latest model (epoch 29, total_steps 18816)\n",
      "saving the latest model (epoch 29, total_steps 18880)\n",
      "saving the latest model (epoch 29, total_steps 18944)\n",
      "saving the latest model (epoch 29, total_steps 19008)\n",
      "saving the latest model (epoch 29, total_steps 19072)\n",
      "saving the latest model (epoch 29, total_steps 19136)\n",
      "saving the latest model (epoch 29, total_steps 19200)\n",
      "saving the model at the end of epoch 29, iters 19200\n",
      "End of epoch 29 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 30, total_steps 19264)\n",
      "saving the latest model (epoch 30, total_steps 19328)\n",
      "saving the latest model (epoch 30, total_steps 19392)\n",
      "saving the latest model (epoch 30, total_steps 19456)\n",
      "saving the latest model (epoch 30, total_steps 19520)\n",
      "saving the latest model (epoch 30, total_steps 19584)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the latest model (epoch 30, total_steps 19648)\n",
      "saving the latest model (epoch 30, total_steps 19712)\n",
      "saving the latest model (epoch 30, total_steps 19776)\n",
      "saving the latest model (epoch 30, total_steps 19840)\n",
      "saving the model at the end of epoch 30, iters 19840\n",
      "End of epoch 30 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 31, total_steps 19904)\n",
      "saving the latest model (epoch 31, total_steps 19968)\n",
      "saving the latest model (epoch 31, total_steps 20032)\n",
      "saving the latest model (epoch 31, total_steps 20096)\n",
      "saving the latest model (epoch 31, total_steps 20160)\n",
      "saving the latest model (epoch 31, total_steps 20224)\n",
      "saving the latest model (epoch 31, total_steps 20288)\n",
      "saving the latest model (epoch 31, total_steps 20352)\n",
      "saving the latest model (epoch 31, total_steps 20416)\n",
      "saving the latest model (epoch 31, total_steps 20480)\n",
      "saving the model at the end of epoch 31, iters 20480\n",
      "End of epoch 31 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 32, total_steps 20544)\n",
      "saving the latest model (epoch 32, total_steps 20608)\n",
      "saving the latest model (epoch 32, total_steps 20672)\n",
      "saving the latest model (epoch 32, total_steps 20736)\n",
      "saving the latest model (epoch 32, total_steps 20800)\n",
      "saving the latest model (epoch 32, total_steps 20864)\n",
      "saving the latest model (epoch 32, total_steps 20928)\n",
      "saving the latest model (epoch 32, total_steps 20992)\n",
      "saving the latest model (epoch 32, total_steps 21056)\n",
      "saving the latest model (epoch 32, total_steps 21120)\n",
      "saving the model at the end of epoch 32, iters 21120\n",
      "End of epoch 32 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 33, total_steps 21184)\n",
      "saving the latest model (epoch 33, total_steps 21248)\n",
      "saving the latest model (epoch 33, total_steps 21312)\n",
      "saving the latest model (epoch 33, total_steps 21376)\n",
      "saving the latest model (epoch 33, total_steps 21440)\n",
      "saving the latest model (epoch 33, total_steps 21504)\n",
      "saving the latest model (epoch 33, total_steps 21568)\n",
      "saving the latest model (epoch 33, total_steps 21632)\n",
      "saving the latest model (epoch 33, total_steps 21696)\n",
      "saving the latest model (epoch 33, total_steps 21760)\n",
      "saving the model at the end of epoch 33, iters 21760\n",
      "End of epoch 33 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 34, total_steps 21824)\n",
      "saving the latest model (epoch 34, total_steps 21888)\n",
      "saving the latest model (epoch 34, total_steps 21952)\n",
      "saving the latest model (epoch 34, total_steps 22016)\n",
      "saving the latest model (epoch 34, total_steps 22080)\n",
      "saving the latest model (epoch 34, total_steps 22144)\n",
      "saving the latest model (epoch 34, total_steps 22208)\n",
      "saving the latest model (epoch 34, total_steps 22272)\n",
      "saving the latest model (epoch 34, total_steps 22336)\n",
      "saving the latest model (epoch 34, total_steps 22400)\n",
      "saving the model at the end of epoch 34, iters 22400\n",
      "End of epoch 34 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 35, total_steps 22464)\n",
      "saving the latest model (epoch 35, total_steps 22528)\n",
      "saving the latest model (epoch 35, total_steps 22592)\n",
      "saving the latest model (epoch 35, total_steps 22656)\n",
      "saving the latest model (epoch 35, total_steps 22720)\n",
      "saving the latest model (epoch 35, total_steps 22784)\n",
      "saving the latest model (epoch 35, total_steps 22848)\n",
      "saving the latest model (epoch 35, total_steps 22912)\n",
      "saving the latest model (epoch 35, total_steps 22976)\n",
      "saving the latest model (epoch 35, total_steps 23040)\n",
      "saving the model at the end of epoch 35, iters 23040\n",
      "End of epoch 35 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 36, total_steps 23104)\n",
      "saving the latest model (epoch 36, total_steps 23168)\n",
      "saving the latest model (epoch 36, total_steps 23232)\n",
      "saving the latest model (epoch 36, total_steps 23296)\n",
      "saving the latest model (epoch 36, total_steps 23360)\n",
      "saving the latest model (epoch 36, total_steps 23424)\n",
      "saving the latest model (epoch 36, total_steps 23488)\n",
      "saving the latest model (epoch 36, total_steps 23552)\n",
      "saving the latest model (epoch 36, total_steps 23616)\n",
      "saving the latest model (epoch 36, total_steps 23680)\n",
      "saving the model at the end of epoch 36, iters 23680\n",
      "End of epoch 36 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 37, total_steps 23744)\n",
      "saving the latest model (epoch 37, total_steps 23808)\n",
      "saving the latest model (epoch 37, total_steps 23872)\n",
      "saving the latest model (epoch 37, total_steps 23936)\n",
      "saving the latest model (epoch 37, total_steps 24000)\n",
      "saving the latest model (epoch 37, total_steps 24064)\n",
      "saving the latest model (epoch 37, total_steps 24128)\n",
      "saving the latest model (epoch 37, total_steps 24192)\n",
      "saving the latest model (epoch 37, total_steps 24256)\n",
      "saving the latest model (epoch 37, total_steps 24320)\n",
      "saving the model at the end of epoch 37, iters 24320\n",
      "End of epoch 37 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 38, total_steps 24384)\n",
      "saving the latest model (epoch 38, total_steps 24448)\n",
      "saving the latest model (epoch 38, total_steps 24512)\n",
      "saving the latest model (epoch 38, total_steps 24576)\n",
      "saving the latest model (epoch 38, total_steps 24640)\n",
      "saving the latest model (epoch 38, total_steps 24704)\n",
      "saving the latest model (epoch 38, total_steps 24768)\n",
      "saving the latest model (epoch 38, total_steps 24832)\n",
      "saving the latest model (epoch 38, total_steps 24896)\n",
      "saving the latest model (epoch 38, total_steps 24960)\n",
      "saving the model at the end of epoch 38, iters 24960\n",
      "End of epoch 38 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 39, total_steps 25024)\n",
      "saving the latest model (epoch 39, total_steps 25088)\n",
      "saving the latest model (epoch 39, total_steps 25152)\n",
      "saving the latest model (epoch 39, total_steps 25216)\n",
      "saving the latest model (epoch 39, total_steps 25280)\n",
      "saving the latest model (epoch 39, total_steps 25344)\n",
      "saving the latest model (epoch 39, total_steps 25408)\n",
      "saving the latest model (epoch 39, total_steps 25472)\n",
      "saving the latest model (epoch 39, total_steps 25536)\n",
      "saving the latest model (epoch 39, total_steps 25600)\n",
      "saving the model at the end of epoch 39, iters 25600\n",
      "End of epoch 39 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 40, total_steps 25664)\n",
      "saving the latest model (epoch 40, total_steps 25728)\n",
      "saving the latest model (epoch 40, total_steps 25792)\n",
      "saving the latest model (epoch 40, total_steps 25856)\n",
      "saving the latest model (epoch 40, total_steps 25920)\n",
      "saving the latest model (epoch 40, total_steps 25984)\n",
      "saving the latest model (epoch 40, total_steps 26048)\n",
      "saving the latest model (epoch 40, total_steps 26112)\n",
      "saving the latest model (epoch 40, total_steps 26176)\n",
      "saving the latest model (epoch 40, total_steps 26240)\n",
      "saving the model at the end of epoch 40, iters 26240\n",
      "End of epoch 40 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 41, total_steps 26304)\n",
      "saving the latest model (epoch 41, total_steps 26368)\n",
      "saving the latest model (epoch 41, total_steps 26432)\n",
      "saving the latest model (epoch 41, total_steps 26496)\n",
      "saving the latest model (epoch 41, total_steps 26560)\n",
      "saving the latest model (epoch 41, total_steps 26624)\n",
      "saving the latest model (epoch 41, total_steps 26688)\n",
      "saving the latest model (epoch 41, total_steps 26752)\n",
      "saving the latest model (epoch 41, total_steps 26816)\n",
      "saving the latest model (epoch 41, total_steps 26880)\n",
      "saving the model at the end of epoch 41, iters 26880\n",
      "End of epoch 41 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 42, total_steps 26944)\n",
      "saving the latest model (epoch 42, total_steps 27008)\n",
      "saving the latest model (epoch 42, total_steps 27072)\n",
      "saving the latest model (epoch 42, total_steps 27136)\n",
      "saving the latest model (epoch 42, total_steps 27200)\n",
      "saving the latest model (epoch 42, total_steps 27264)\n",
      "saving the latest model (epoch 42, total_steps 27328)\n",
      "saving the latest model (epoch 42, total_steps 27392)\n",
      "saving the latest model (epoch 42, total_steps 27456)\n",
      "saving the latest model (epoch 42, total_steps 27520)\n",
      "saving the model at the end of epoch 42, iters 27520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 42 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 43, total_steps 27584)\n",
      "saving the latest model (epoch 43, total_steps 27648)\n",
      "saving the latest model (epoch 43, total_steps 27712)\n",
      "saving the latest model (epoch 43, total_steps 27776)\n",
      "saving the latest model (epoch 43, total_steps 27840)\n",
      "saving the latest model (epoch 43, total_steps 27904)\n",
      "saving the latest model (epoch 43, total_steps 27968)\n",
      "saving the latest model (epoch 43, total_steps 28032)\n",
      "saving the latest model (epoch 43, total_steps 28096)\n",
      "saving the latest model (epoch 43, total_steps 28160)\n",
      "saving the model at the end of epoch 43, iters 28160\n",
      "End of epoch 43 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 44, total_steps 28224)\n",
      "saving the latest model (epoch 44, total_steps 28288)\n",
      "saving the latest model (epoch 44, total_steps 28352)\n",
      "saving the latest model (epoch 44, total_steps 28416)\n",
      "saving the latest model (epoch 44, total_steps 28480)\n",
      "saving the latest model (epoch 44, total_steps 28544)\n",
      "saving the latest model (epoch 44, total_steps 28608)\n",
      "saving the latest model (epoch 44, total_steps 28672)\n",
      "saving the latest model (epoch 44, total_steps 28736)\n",
      "saving the latest model (epoch 44, total_steps 28800)\n",
      "saving the model at the end of epoch 44, iters 28800\n",
      "End of epoch 44 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 45, total_steps 28864)\n",
      "saving the latest model (epoch 45, total_steps 28928)\n",
      "saving the latest model (epoch 45, total_steps 28992)\n",
      "saving the latest model (epoch 45, total_steps 29056)\n",
      "saving the latest model (epoch 45, total_steps 29120)\n",
      "saving the latest model (epoch 45, total_steps 29184)\n",
      "saving the latest model (epoch 45, total_steps 29248)\n",
      "saving the latest model (epoch 45, total_steps 29312)\n",
      "saving the latest model (epoch 45, total_steps 29376)\n",
      "saving the latest model (epoch 45, total_steps 29440)\n",
      "saving the model at the end of epoch 45, iters 29440\n",
      "End of epoch 45 / 50 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 46, total_steps 29504)\n",
      "saving the latest model (epoch 46, total_steps 29568)\n",
      "saving the latest model (epoch 46, total_steps 29632)\n",
      "saving the latest model (epoch 46, total_steps 29696)\n",
      "saving the latest model (epoch 46, total_steps 29760)\n",
      "saving the latest model (epoch 46, total_steps 29824)\n",
      "saving the latest model (epoch 46, total_steps 29888)\n",
      "saving the latest model (epoch 46, total_steps 29952)\n",
      "saving the latest model (epoch 46, total_steps 30016)\n",
      "saving the latest model (epoch 46, total_steps 30080)\n",
      "saving the model at the end of epoch 46, iters 30080\n",
      "End of epoch 46 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 47, total_steps 30144)\n",
      "saving the latest model (epoch 47, total_steps 30208)\n",
      "saving the latest model (epoch 47, total_steps 30272)\n",
      "saving the latest model (epoch 47, total_steps 30336)\n",
      "saving the latest model (epoch 47, total_steps 30400)\n",
      "saving the latest model (epoch 47, total_steps 30464)\n",
      "saving the latest model (epoch 47, total_steps 30528)\n",
      "saving the latest model (epoch 47, total_steps 30592)\n",
      "saving the latest model (epoch 47, total_steps 30656)\n",
      "saving the latest model (epoch 47, total_steps 30720)\n",
      "saving the model at the end of epoch 47, iters 30720\n",
      "End of epoch 47 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 48, total_steps 30784)\n",
      "saving the latest model (epoch 48, total_steps 30848)\n",
      "saving the latest model (epoch 48, total_steps 30912)\n",
      "saving the latest model (epoch 48, total_steps 30976)\n",
      "saving the latest model (epoch 48, total_steps 31040)\n",
      "saving the latest model (epoch 48, total_steps 31104)\n",
      "saving the latest model (epoch 48, total_steps 31168)\n",
      "saving the latest model (epoch 48, total_steps 31232)\n",
      "saving the latest model (epoch 48, total_steps 31296)\n",
      "saving the latest model (epoch 48, total_steps 31360)\n",
      "saving the model at the end of epoch 48, iters 31360\n",
      "End of epoch 48 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 49, total_steps 31424)\n",
      "saving the latest model (epoch 49, total_steps 31488)\n",
      "saving the latest model (epoch 49, total_steps 31552)\n",
      "saving the latest model (epoch 49, total_steps 31616)\n",
      "saving the latest model (epoch 49, total_steps 31680)\n",
      "saving the latest model (epoch 49, total_steps 31744)\n",
      "saving the latest model (epoch 49, total_steps 31808)\n",
      "saving the latest model (epoch 49, total_steps 31872)\n",
      "saving the latest model (epoch 49, total_steps 31936)\n",
      "saving the latest model (epoch 49, total_steps 32000)\n",
      "saving the model at the end of epoch 49, iters 32000\n",
      "End of epoch 49 / 50 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 50, total_steps 32064)\n",
      "saving the latest model (epoch 50, total_steps 32128)\n",
      "saving the latest model (epoch 50, total_steps 32192)\n",
      "saving the latest model (epoch 50, total_steps 32256)\n",
      "saving the latest model (epoch 50, total_steps 32320)\n",
      "saving the latest model (epoch 50, total_steps 32384)\n",
      "saving the latest model (epoch 50, total_steps 32448)\n",
      "saving the latest model (epoch 50, total_steps 32512)\n",
      "saving the latest model (epoch 50, total_steps 32576)\n",
      "saving the latest model (epoch 50, total_steps 32640)\n",
      "saving the model at the end of epoch 50, iters 32640\n",
      "End of epoch 50 / 50 \t Time Taken: 55 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "opt = SimpleNamespace(\n",
    "    epoch_count=0,\n",
    "    niter=50,\n",
    "    niter_decay = 0,\n",
    "    print_freq = 1,\n",
    "    batchSize = batch_size,\n",
    "    display_freq = 1,\n",
    "    update_html_freq = 1,\n",
    "    display_id = 4,\n",
    "    save_latest_freq = 1,\n",
    "    isTrain = True,\n",
    "    gpu_ids = list(range(torch.cuda.device_count())),\n",
    "    checkpoints_dir='/scratch/jtc440/cyclegan',\n",
    "    name='tidegan',\n",
    "    model_size=64,\n",
    "    ngpus=1,\n",
    "    num_channels=1,\n",
    "    latent_dim=100,\n",
    "    alpha=0.2,\n",
    "    post_proc_filt_len=512,\n",
    "    batch_shuffle=False,\n",
    "    verbose=False,\n",
    "    shift_factor=2,\n",
    "    pool_size=50,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    "    lambda_identity=0.5,\n",
    "    batches_per_epoch=10,\n",
    "    lambda_A=10,\n",
    "    lambda_B=10,\n",
    "    no_lsgan=False,\n",
    "    which_direction='AtoB',\n",
    "    lr_policy='lambda',\n",
    "    lr_decay_iters=50,\n",
    "    use_cuda=True,\n",
    "    save_epoch_freq=1,\n",
    ")\n",
    "\n",
    "model_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model = CycleGANModel()\n",
    "model.initialize(opt)\n",
    "#visualizer = Visualizer(opt)\n",
    "total_steps = 0\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for batch_idx in range(opt.batches_per_epoch):\n",
    "        data_A = np_to_input_tensor(next(genA)['X'], use_cuda=opt.use_cuda)\n",
    "        data_B = np_to_input_tensor(next(genB)['X'], use_cuda=opt.use_cuda)  \n",
    "        data = {'A': data_A, 'B': data_B, 'A_paths': [], 'B_paths': []}\n",
    "        \n",
    "        iter_start_time = time.time()\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        #visualizer.reset()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if total_steps % opt.display_freq == 0:\n",
    "            save_result = total_steps % opt.update_html_freq == 0\n",
    "            save_tidegan_samples(opt.checkpoints_dir, model.get_current_audibles(), total_steps)\n",
    "            #visualizer.display_current_results(, epoch, save_result)\n",
    "\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            #visualizer.print_current_errors(epoch, epoch_iter, errors, t, t_data)\n",
    "            #if opt.display_id > 0:\n",
    "            #    visualizer.plot_current_errors(epoch, float(epoch_iter) / dataset_size, opt, errors)\n",
    "\n",
    "        if total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' %\n",
    "                  (epoch, total_steps))\n",
    "            model.save('latest')\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "              (epoch, total_steps))\n",
    "        model.save('latest')\n",
    "        model.save(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
